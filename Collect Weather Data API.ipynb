{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from collections import namedtuple\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = '9b47f685a716d06d'\n",
    "BASE_URL = 'http://api.wunderground.com/api/{}/history_{}/q/TX/Round_Rock.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"date\", \"meantempm\", \"meandewptm\", \"meanpressurem\", \"maxhumidity\", \"minhumidity\", \"maxtempm\",\n",
    "           \"mintempm\", \"maxdewptm\", \"mindewptm\", \"maxpressurem\", \"minpressurem\", \"precipm\"]\n",
    "DailySummary = namedtuple('DailySummary', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do - add print function calls to this function to show progress\n",
    "def extract_weather_data(url, api_key, target_date, days):  \n",
    "    records = []\n",
    "    for _ in range(days):\n",
    "        request = BASE_URL.format(API_KEY, target_date.strftime('%Y%m%d'))\n",
    "        response = requests.get(request)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()['history']['dailysummary'][0]\n",
    "            records.append(DailySummary(\n",
    "                date=target_date,\n",
    "                meantempm=data['meantempm'],\n",
    "                meandewptm=data['meandewptm'],\n",
    "                meanpressurem=data['meanpressurem'],\n",
    "                maxhumidity=data['maxhumidity'],\n",
    "                minhumidity=data['minhumidity'],\n",
    "                maxtempm=data['maxtempm'],\n",
    "                mintempm=data['mintempm'],\n",
    "                maxdewptm=data['maxdewptm'],\n",
    "                mindewptm=data['mindewptm'],\n",
    "                maxpressurem=data['maxpressurem'],\n",
    "                minpressurem=data['minpressurem'],\n",
    "                precipm=data['precipm']))\n",
    "        time.sleep(6)\n",
    "        target_date += timedelta(days=1)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not run this cell when collecting data on day 2\n",
    "def get_target_date():\n",
    "    \"\"\"Return target date 1000 days prior to current date.\"\"\"\n",
    "    current_date = datetime.now()\n",
    "    target_date = current_date - timedelta(days=1000)\n",
    "    return target_date\n",
    "\n",
    "target_date = get_target_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# records = extract_weather_data(BASE_URL, API_KEY, target_date, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DailySummary(date=datetime.datetime(2015, 8, 24, 0, 0), meantempm='30', meandewptm='21', meanpressurem='1017', maxhumidity='100', minhumidity='32', maxtempm='37', mintempm='23', maxdewptm='24', mindewptm='18', maxpressurem='1020', minpressurem='1015', precipm='0.00'),\n",
       " DailySummary(date=datetime.datetime(2015, 8, 25, 0, 0), meantempm='30', meandewptm='21', meanpressurem='1018', maxhumidity='94', minhumidity='39', maxtempm='36', mintempm='24', maxdewptm='23', mindewptm='19', maxpressurem='1019', minpressurem='1016', precipm='0.00'),\n",
       " DailySummary(date=datetime.datetime(2015, 8, 26, 0, 0), meantempm='28', meandewptm='20', meanpressurem='1019', maxhumidity='100', minhumidity='36', maxtempm='35', mintempm='21', maxdewptm='23', mindewptm='18', maxpressurem='1021', minpressurem='1017', precipm='0.00'),\n",
       " DailySummary(date=datetime.datetime(2015, 8, 27, 0, 0), meantempm='28', meandewptm='18', meanpressurem='1017', maxhumidity='94', minhumidity='26', maxtempm='35', mintempm='21', maxdewptm='22', mindewptm='13', maxpressurem='1020', minpressurem='1015', precipm='0.00'),\n",
       " DailySummary(date=datetime.datetime(2015, 8, 28, 0, 0), meantempm='28', meandewptm='17', meanpressurem='1015', maxhumidity='88', minhumidity='30', maxtempm='35', mintempm='20', maxdewptm='19', mindewptm='14', maxpressurem='1017', minpressurem='1013', precipm='0.00')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at first five records\n",
    "records[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save records list\n",
    "# with open('records_pt1.pkl', 'wb') as f:\n",
    "#     pickle.dump(records, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load records list - still need to run cells 1-4\n",
    "with open('records_pt1.pkl', 'rb') as fp:\n",
    "    records = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DailySummary(date=datetime.datetime(2018, 5, 20, 0, 0), meantempm='23', meandewptm='22', meanpressurem='1015', maxhumidity='100', minhumidity='70', maxtempm='28', mintempm='19', maxdewptm='24', mindewptm='19', maxpressurem='1018', minpressurem='1011', precipm='10.41')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect last record to date; next target date should be plus one day\n",
    "records[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new target date based on date above plus one day\n",
    "target_date = datetime(2018, 2, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this 5 separate times after setting the target date\n",
    "records += extract_weather_data(BASE_URL, API_KEY, target_date, 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('records_pt2.pkl', 'wb') as f:\n",
    "    pickle.dump(records, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load records list - still need to run cells 1 and 3\n",
    "with open('records_pt2.pkl', 'rb') as fp:\n",
    "    records = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(records, columns=features).set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df[['meantempm', 'meandewptm']].head(10)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 day prior\n",
    "N = 1\n",
    "\n",
    "# target measurement of mean temperature\n",
    "feature = 'meantempm'\n",
    "\n",
    "# total number of rows\n",
    "rows = tmp.shape[0]\n",
    "\n",
    "# a list representing Nth prior measurements of feature\n",
    "# notice that the front of the list needs to be padded with N\n",
    "# None values to maintain the consistent rows length for each N\n",
    "nth_prior_measurements = [None]*N + [tmp[feature][i-N] for i in range(N, rows)]\n",
    "\n",
    "# makee a new column name of feature_N and add to DataFrame\n",
    "col_name = '{}_{}'.format(feature, N)\n",
    "tmp[col_name] = nth_prior_measurements\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_nth_day_feature(df, feature, N):\n",
    "    rows = df.shape[0]\n",
    "    nth_prior_measurements = [None]*N + [df[feature][i-N] for i in range(N, rows)]\n",
    "    col_name = '{}_{}'.format(feature, N)\n",
    "    df[col_name] = nth_prior_measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features:\n",
    "    if feature != 'date':\n",
    "        for N in range(1, 4):\n",
    "            derive_nth_day_feature(df, feature, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of original features without meantempm, mintempm, and maxtempm\n",
    "to_remove = [feature\n",
    "             for feature in features\n",
    "             if feature not in ['meantempm', 'mintempm', 'maxtempm']]\n",
    "\n",
    "# make a list of columns to keep\n",
    "to_keep = [col for col in df.columns if col not in to_remove]\n",
    "\n",
    "# select only the columns in to_keep and assign to df\n",
    "df = df[to_keep]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call describe on df and transpose it due to the large number of columns\n",
    "spread = df.describe().T\n",
    "\n",
    "# precalculate interquartile range for ease of use in next calculation\n",
    "IQR = spread['75%'] - spread['25%']\n",
    "\n",
    "# create an outliers column which is either 3 IQRs below the first quartile or\n",
    "# 3 IQRs above the third quartile\n",
    "spread['outliers'] = (spread['min']<(spread['25%']-(3*IQR)))|(spread['max'] > (spread['75%']+3*IQR))\n",
    "\n",
    "# just display the features containing extreame outliers\n",
    "spread.ix[spread.outliers,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [14, 8]\n",
    "df.maxhumidity_1.hist()\n",
    "plt.title('Distribution of maxhumidity_1')\n",
    "plt.xlabel('maxhumidity_1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.minpressurem_1.hist()\n",
    "plt.title('Distribution of minpressurem_1')\n",
    "plt.xlabel('minpressurem_1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over the precip columns\n",
    "for precip_col in ['precipm_1', 'precipm_2', 'precipm_3']:\n",
    "    # create a boolean array of values representing nans\n",
    "    missing_vals = pd.isnull(df[precip_col])\n",
    "    df[precip_col][missing_vals] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "with open('end-part1_df.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
